{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "\n",
    "from langchain_openai import ChatOpenAI,OpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "from transformers import (AutoTokenizer,\n",
    "                          AutoModelForCausalLM,\n",
    "                          BitsAndBytesConfig,\n",
    "                          pipeline)\n",
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =pd.read_csv(\"data/Clothing/clothingClear.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"clothingID\"].sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetID = 1110\n",
    "filteredDF = data[data[\"clothingID\"]==targetID]\n",
    "filteredDF.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filteredDF[\"rating\"].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewList = filteredDF[\"cleanReview\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_data = json.load(open(\"config.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data ' dan target id ye göre filtrleme yapar ve reviewleri text list olarak döndürür.\n",
    "def reviewListGenarator(data,targetID):\n",
    "    filteredDF = data[data[\"clothingID\"]==targetID]\n",
    "    print(f\"Review Count {len(filteredDF)}\")\n",
    "    reviewList = filteredDF[\"cleanReview\"].tolist()\n",
    "    return reviewList\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reviewleri birleştirir ve promt oluşturur.\n",
    "def inputGenerator(reviewList):\n",
    "    template = \"\"\" Analyze the user reviews provided below and create a concise paragraph summarizing the overall sentiment. Your summary should answer the following questions: Do users generally like or dislike the dress? What features are most appreciated or criticized? Do users recommend the dress? Include any additional informations observed, but keep the output as a single cohesive paragraph. Here are the user reviews:\n",
    "    {revs}\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"revs\"],\n",
    "        template=template\n",
    "    )\n",
    "    \n",
    "    text = \"Review: \"+\" Review: \".join(reviewList)\n",
    "    inputText = prompt.format(revs=text)\n",
    "    return inputText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "API_KEY=config_data[\"GPT_API_KEY\"]\n",
    "GPT_TOKEN_LIMIT=128000\n",
    "gptModel = ChatOpenAI(model=\"gpt-4o-mini\",openai_api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = inputGenerator(reviewList)\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = gptModel.get_num_tokens(input)\n",
    "print (f\"prompt {num_tokens} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if num_tokens < GPT_TOKEN_LIMIT:\n",
    "    output = gptModel.invoke(input)\n",
    "    print(output.content)\n",
    "else:\n",
    "    print(\"Token boyutu cok buyuk\")\n",
    "    #review listten eleman dropla\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Llama_TOKEN_LIMIT=128000\n",
    "\n",
    "# Llama-3.2 (1B): Requires 1.8 GB of GPU memory. \n",
    "# Llama-3.2 (3B): Needs 3.4 GB of GPU memory.\n",
    "\n",
    "#model_name = \"meta-llama/Llama-3.2-1B\"\n",
    "#model_name = \"meta-llama/Llama-3.2-3B\"\n",
    "#LlamaModelName=\"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "\n",
    "LlamaModelName=\"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "\n",
    "\n",
    "'''\n",
    "Instruction-tuned: Model, belirli görevlerde talimatları daha iyi anlamak için ince ayarlanmıştır. İnsanların verdiği talimatlara yönelik daha alakalı ve doğru sonuçlar verir.\n",
    "Daha kullanıcı dostu yanıtlar üretebilmek için genellikle RLHF (Reinforcement Learning with Human Feedback) ile eğitilir.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HF_TOKEN = config_data[\"HF_TOKEN\"]\n",
    "login(HF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LlamaTokenizer = AutoTokenizer.from_pretrained(LlamaModelName)\n",
    "\n",
    "LlamaTokenizer.pad_token = LlamaTokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LlamaModel = AutoModelForCausalLM.from_pretrained(\n",
    "    LlamaModelName,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=bnb_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LlamaPipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=LlamaModel,\n",
    "    tokenizer=LlamaTokenizer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLlamaPipeResponse(input):\n",
    "  sequences = LlamaPipe(input,return_full_text=False,\n",
    "          max_new_tokens=256)\n",
    "  gen_text = sequences[0][\"generated_text\"]\n",
    "  return gen_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input = inputGenerator(reviewList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llamaTokens = LlamaTokenizer(input)\n",
    "llamaTokenCount = len(llamaTokens['input_ids'])\n",
    "llamaTokenCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "getLlamaPipeResponse(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if llamaTokenCount < Llama_TOKEN_LIMIT:\n",
    "    output = getLlamaPipeResponse(input)\n",
    "    print(output)\n",
    "else:\n",
    "    print(\"Token boyutu cok buyuk\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mistral 2k\n",
    "#Minerva 2k\n",
    "# falcon 2k\n",
    "#bigscience/bloomz-1b7  CUDA out of memory. Tried to allocate 5.00 GiB. GPU 0 has a total capacity of 4.00 GiB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "#XModelName = \"Qwen/Qwen2.5-3B-Instruct\"\n",
    "XModelName=\"Qwen/Qwen2-1.5B-Instruct\"\n",
    "max = 32768\n",
    "\n",
    "XModel = AutoModelForCausalLM.from_pretrained(XModelName,\n",
    "                                                    device_map=\"auto\",\n",
    "                                                    quantization_config=bnb_config,\n",
    "                                                    torch_dtype=torch.float16)\n",
    "\n",
    "\n",
    "XTokenizer = AutoTokenizer.from_pretrained(XModelName)\n",
    "XTokenizer.pad_token = XTokenizer.eos_token\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XPipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=XModel,\n",
    "    tokenizer=XTokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = inputGenerator(reviewList)\n",
    "tokens = XTokenizer(input)\n",
    "token_count = len(tokens['input_ids'])\n",
    "token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = inputGenerator(reviewList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "XPipe(input,return_full_text=False,max_new_tokens=256)[0][\"generated_text\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
